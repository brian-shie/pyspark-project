{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ddd8b0-80fc-4af5-af29-9dc8ebf62e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from textblob import TextBlob\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "# stopwordList = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3092fa1-3d40-4c77-9bc0-ec8a99802f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # create Spark session\n",
    "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "    # read the tweet data from socket\n",
    "    lines = spark.readStream.format(\"socket\").option(\"host\", \"127.0.0.1\").option(\"port\", 9999).load()\n",
    "#     remover = StopWordsRemover(inputCol='word', outputCol=\"stopWordsRem\", stopWords=stopwordList)\n",
    "    \n",
    "    words = lines.select(\n",
    "        explode(\n",
    "            split(lower(lines.value), \" \")\n",
    "        ).alias('word')\n",
    "    )\n",
    "    words = words.filter((words.word == 'buy')  | \n",
    "                         (words.word == 'sell') |\n",
    "                         (words.word == 'bull') |\n",
    "                         (words.word == 'bear') |\n",
    "                         (words.word == 'moon') |\n",
    "                         (words.word == 'crash'))\n",
    "    \n",
    "#     words = words.filter(words['word'] == '')\n",
    "#     words = lines.select(\n",
    "#         explode(\n",
    "#             split(\n",
    "#                 remover.transform(lower(lines.value).alias('word')).select(\"stopWordsRem\").alias('word'),\n",
    "#                 \" \")\n",
    "#         ).alias(\"word\")\n",
    "#     )\n",
    "    wordCounts = words.groupBy(\"word\").count()\n",
    "    \n",
    "    query =  wordCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"streaming_data\") \\\n",
    "    .trigger(processingTime='3 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb496060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM streaming_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb0c028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['word'] == i).select('count').head()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77bae7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [0, 0, 0]\n",
    "input_list = ['buy', 'bull', 'moon', 'sell', 'bear', 'crash']\n",
    "\n",
    "for i in input_list[0:3]:\n",
    "    try:\n",
    "        inputs[0] += df.filter(df['word'] == i).select('count').head()[0]\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "for i in input_list[3:6]:\n",
    "    try:\n",
    "        inputs[1] += df.filter(df['word'] == i).select('count').head()[0]\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "inputs[2] = inputs[0] - inputs[1]\n",
    "\n",
    "try:\n",
    "    inputs -= last_state\n",
    "    \n",
    "except Exception:\n",
    "    pass\n",
    "    \n",
    "last_state = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cfbb978b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 1, 40]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e085d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n",
      "821\n",
      "821\n",
      "821\n",
      "821\n",
      "821\n",
      "821\n",
      "821\n",
      "821\n",
      "821\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "for i in range(10):\n",
    "    print(len(spark.sql(\"SELECT * FROM streaming_data\").toPandas()))\n",
    "#     sns.barplot(x = 'word', y = 'count', data = pandas_df.iloc[0:5,:]);\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c7bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce7a5c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                word|count|\n",
      "+--------------------+-----+\n",
      "|            euphoria|   13|\n",
      "|                  in|    5|\n",
      "|                  is|    4|\n",
      "|                    |    4|\n",
      "|           #euphoria|    4|\n",
      "|                  de|    4|\n",
      "|                   o|    4|\n",
      "|                 que|    4|\n",
      "|                  ta|    3|\n",
      "|              parece|    3|\n",
      "|               maddy|    3|\n",
      "|                foto|    3|\n",
      "|          euphoriart|    3|\n",
      "|                essa|    3|\n",
      "|         @pwrsphone:|    3|\n",
      "|https://t.co/dsrk...|    3|\n",
      "|                 s2,|    3|\n",
      "|                 ep4|    3|\n",
      "|                  em|    3|\n",
      "|             douglas|    3|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM streaming_data\").orderBy('count', ascending = False)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c73dcaab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9448/3867741903.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbernoulli\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinear_QNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQTrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdogAI\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDogGameAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhelper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from scipy.stats import bernoulli\n",
    "from model import Linear_QNet, QTrainer\n",
    "from dogAI import DogGameAI\n",
    "from helper import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from scipy.stats import bernoulli\n",
    "from model import Linear_QNet, QTrainer\n",
    "from dogAI import DogGameAI\n",
    "from helper import plot\n",
    "\n",
    "max_memory = 100_000\n",
    "batch_size = 1000\n",
    "learning_rate = 0.005\n",
    "\n",
    "class Agent:\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.n_games = 0\n",
    "\t\tself.epsilon = 0 # aleatoriedade\n",
    "\t\tself.gamma = 0 # taxa de desconto\n",
    "\t\tself.memory = deque(maxlen = max_memory) # se alcanÃ§a o limite: popleft()\n",
    "\t\tself.model = Linear_QNet(10, 256, 5)\n",
    "\t\tself.trainer = QTrainer(self.model, lr=learning_rate, gamma=self.gamma)\n",
    "\n",
    "\tdef get_state(self, game):\n",
    "\t\tstate = [\n",
    "\t\t\tgame.player.x, game.player.y, game.player.mana, game.score, # Player\n",
    "\t\t\tgame.biscoito.x, game.biscoito.y, # Biscoito\n",
    "\t\t\tgame.monster_1.x, game.monster_1.y, game.monster_2.x, game.monster_2.y # Mobs\n",
    "\t\t]\n",
    "\n",
    "\t\treturn state\n",
    "\n",
    "\tdef remember(self, state, action, reward, next_state, game_over):\n",
    "\t\tself.memory.append((state, action, reward, next_state, game_over))\n",
    "\n",
    "\tdef train_long_memory(self):\n",
    "\t\tif len(self.memory) > batch_size:\n",
    "\t\t\tmini_sample = random.sample(self.memory, batch_size) # list of tuples\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tmini_sample = self.memory\n",
    "\n",
    "\t\tstates, actions, rewards, next_states, game_overs = zip(*mini_sample)\n",
    "\t\tself.trainer.train_step(states, actions, rewards, next_states, game_overs)\n",
    "\n",
    "\tdef train_short_memory(self, state, action, reward, next_state, game_over):\n",
    "\t\tself.trainer.train_step(state, action, reward, next_state, game_over)\n",
    "\n",
    "\tdef get_action(self, state):\n",
    "\t\t# random moves: tradeoff exploration / exploitation\n",
    "\t\t# self.epsilon = 620 - 100*np.log(self.n_games)\n",
    "\t\tself.epsilon = 150 - self.n_games\n",
    "\t\tfinal_move = [0, 0, 0, 0, 0, 0]\n",
    "\t\tif random.randint(0, 200) < self.epsilon:\n",
    "\t\t\tfinal_move = torch.tensor(bernoulli.rvs(size = 5, p = 0.5), dtype = int)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tstate0 =  torch.tensor(state, dtype=torch.float)\n",
    "\t\t\tfinal_move = self.model(state0)\n",
    "\t\t\tprint(final_move)\n",
    "\n",
    "\t\t# print(type(final_move))\n",
    "\n",
    "\t\treturn final_move\n",
    "\n",
    "def train():\n",
    "\tplot_scores = []\n",
    "\tplot_mean_scores = []\n",
    "\ttotal_score = 0\n",
    "\tbest_score = 0\n",
    "\tagent = Agent()\n",
    "\tgame = DogGameAI()\n",
    "\twhile True:\n",
    "\t\t# get old state\n",
    "\t\tstate_old = agent.get_state(game)\n",
    "\n",
    "\t\t# get move\n",
    "\t\tfinal_move = agent.get_action(state_old)\n",
    "\n",
    "\t\t# perform move and get new state\n",
    "\t\treward, done, score = game.play_step(final_move)\n",
    "\t\tstate_new = agent.get_state(game)\n",
    "\n",
    "\t\t# train short memory\n",
    "\t\tagent.train_short_memory(state_old, final_move, reward, state_new, game.game_over)\n",
    "\n",
    "\t\t# remember\n",
    "\t\tagent.remember(state_old, final_move, reward, state_new, game.game_over)\n",
    "\n",
    "\t\tif game.game_over:\n",
    "\t\t\t# train long memory / replay memory / experience replay\n",
    "\t\t\tgame.reset()\n",
    "\t\t\tagent.n_games += 1\n",
    "\t\t\tagent.train_long_memory()\n",
    "\n",
    "\t\t\tif score > best_score:\n",
    "\t\t\t\tbest_score = score\n",
    "\t\t\t\tagent.model.save()\n",
    "\n",
    "\t\t\tprint(f\"Game:{agent.n_games} Score {score} Best Score {best_score} \")\n",
    "\n",
    "\t\t\tplot_scores.append(score)\n",
    "\t\t\ttotal_score += score\n",
    "\t\t\tmean_score = total_score / agent.n_games\n",
    "\t\t\tplot_mean_scores.append(mean_score)\n",
    "\t\t\tplot(plot_scores, plot_mean_scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\ttrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0a1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46e2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6277891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rate\":0.00003106824934034432,\"volume\":4228292276,\"cap\":18319975045}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://api.livecoinwatch.com/coins/single\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"currency\": \"USD\",\n",
    "  \"code\": \"SHIB\",\n",
    "  \"meta\": False\n",
    "})\n",
    "headers = {\n",
    "  'content-type': 'application/json',\n",
    "  'x-api-key': 'be34977f-9765-404f-ab83-a97678e83da2'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eda34058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.106824934034432e-05"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(response.text.split(',')[0].split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7389128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark]",
   "language": "python",
   "name": "conda-env-pyspark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
